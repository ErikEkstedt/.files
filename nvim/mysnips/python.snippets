priority 150

# tensorboardx

snippet tensorboardx "expanduser"
from tensorboardX import SummaryWriter

writer = SummaryWriter()
$0
endsnippet

# os

snippet ifans "input conditional"
ans = input("\n> $1? (y/n)")
if ans.lower() == 'y':
	$0
endsnippet

snippet expanduser "expanduser"
home = os.path.expanduser('~')
$0
endsnippet

# Argparse

snippet argparse "argparse snippet"
import argparse
parser = argparse.ArgumentParser(description='$1')
parser.add_argument('--$2', type='$3', default='$4')
args = parser.parse_args()
$0
endsnippet


# Imports
snippet importTorch "pytorch imports"
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
$0
endsnippet

snippet importDataset "pytorch dataset, dataloader"
from torch.utils.data import Dataset, DataLoader
$0
endsnippet

snippet importDefaults  "numpy, matplotlib"
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
$0
endsnippet


# Pytorch
snippet classTorch "class pytorch"
class ${1:MyClass}(nn.Module):
	def __init__(self$2):
		super($1, self).__init__()
		$0

	def forward(self, x):
		return x

endsnippet

snippet Dataset "Pytorch Dataset Class"
class ${1:MyDataset}(Dataset):

	def __init__(self):
		$0

	def __len__(self):
		pass

	def __getitem__(self, idx):
		pass
endsnippet

snippet get_dataloader "dataloader with training split"
def get_data_loader(${1:dataset_path}, train_split=0.9, **kwargs):
	dset = ${2:Dataset}(dataset_path) 

	train_size = int(len(dset) * train_split)
	test_size = len(dset) - train_size
	train_dset, test_dset = torch.utils.data.random_split(dset, [train_size, test_size])

	train_loader = DataLoader(train_dset, **kwargs)
	test_loader = DataLoader(test_dset, **kwargs)

	return train_loader, test_loader
endsnippet


snippet cuda "use cuda pytorch"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
$0
endsnippet

snippet device "use cuda pytorch"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
$0
endsnippet

# AllenNLP
snippet DatasetReader "class datasetreader AllenNLP"
class ${1:MyClass}(DatasetReader):
	def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:
		super().__init__(lazy=False)
		self.token_indexers = token_indexers or {"tokens": SingleIdTokenIndexer()}

	def text_to_instance(self, tokens: List[Token], tags: List[str] = None) -> Instance:
		sentence_field = TextField(tokens, self.token_indexers)
		fields = {"sentence": sentence_field}

		if tags:
			label_field = SequenceLabelField(labels=tags, sequence_field=sentence_field)
			fields["labels"] = label_field

		return Instance(fields)

	def _read(self, file_path: str) -> Iterator[Instance]:
		with open(file_path) as f:
			for line in f:
			pairs = line.strip().split()
			sentence, tags = zip(*(pair.split("###") for pair in pairs))
			yield self.text_to_instance([Token(word) for word in sentence], tags)
endsnippet


snippet classAllenNLPModel "class AllenNLP model"
@Model.register("$2")
class ${1:MyModel}(nn.Module):
	def __init__(self, vocab: Vocabulary,
							 text_field_embedder: TextFieldEmbedder,
							 encoder: Seq2VecEncoder,
							 initializer: InitializerApplicator = InitializerApplicator(),
							 regularizer: Optional[RegularizerApplicator] = None) -> None:
		super($1, self).__init__(vocab, regularizer)
		$0

		self.text_field_embedder = text_field_embedder
		self.encoder = encoder

		# Check that embedding matcher encoder
		if text_field_embedder.get_output_dim() != encoder.get_input_dim():
			raise ConfigurationError("The output dimension of the text_field_embedder must match the "
					"input dimension of the title_encoder. Found {} and {}, "
					"respectively.".format(text_field_embedder.get_output_dim(),
						encoder.get_input_dim()))
			self.metrics = {
				"accuracy": CategoricalAccuracy(),
				"accuracy3": CategoricalAccuracy(top_k=3)
			}
			self.loss = torch.nn.CrossEntropyLoss()

			# Initializer
			initializer(self)

		@overrides
		def forward(self, data: Dict[str, torch.LongTensor]) -> Dict[str, torch.Tensor]:
			"""
			Forward pass
			"""
			pass

		@overrides
		def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
			"""
			Used during prediction
			"""
			pass

		@overrides
		def get_metrics(self, reset: bool = False) -> Dict[str, float]:
			return {metric_name: metric.get_metric(reset) for metric_name, metric in self.metrics.items()}
endsnippet



# Python
snippet main "name is main"
if __name__ == '__main__':
endsnippet

snippet input "generic user input"
input('Press Enter to continue')
endsnippet

snippet answer "user input answer"
ans = input('$0\n> ')
endsnippet

snippet csv "read a csv file"
with open(path, 'r') as f:
	reader = csv.reader(f)
	csv_data = [r for r in reader]
$0
endsnippet

snippet json "read a json file"
with open(path, 'r') as f:
	json_data = json.loads(f.read())
$0
endsnippet

##########
# COMMON #
##########
# The smart def and smart class snippets use a global option called
# "g:ultisnips_python_style" which, if set to "doxygen" will use doxygen
# style comments in docstrings.

global !p

NORMAL  = 0x1
DOXYGEN = 0x2
SPHINX  = 0x3
GOOGLE  = 0x4
NUMPY   = 0x5
JEDI    = 0x6

SINGLE_QUOTES = "'"
DOUBLE_QUOTES = '"'
TRIPLE_QUOTES = '"""'

class Arg(object):
	def __init__(self, arg):
		self.arg = arg
		self.name = arg.split('=')[0].strip()

	def __str__(self):
		return self.name

	def __unicode__(self):
		return self.name

	def is_kwarg(self):
		return '=' in self.arg


def get_args(arglist):
	args = [Arg(arg) for arg in arglist.split(',') if arg]
	args = [arg for arg in args if arg.name != 'self']
	return args


def get_quoting_style(snip):
	style = snip.opt("g:ultisnips_python_quoting_style", "double")
	if style == 'single':
		return SINGLE_QUOTES
	return DOUBLE_QUOTES

def triple_quotes(snip):
	style = snip.opt("g:ultisnips_python_triple_quoting_style")
	if not style:
		return get_quoting_style(snip) * 3
	return (SINGLE_QUOTES if style == 'single' else DOUBLE_QUOTES) * 3

def triple_quotes_handle_trailing(snip, quoting_style):
	"""
	Generate triple quoted strings and handle any trailing quote char,
	which might be there from some autoclose/autopair plugin,
	i.e. when expanding ``"|"``.
	"""
	if not snip.c:
		# Do this only once, otherwise the following error would happen:
		# RuntimeError: The snippets content did not converge: â€¦
		_, col = vim.current.window.cursor
		line = vim.current.line

		# Handle already existing quote chars after the trigger.
		_ret = quoting_style * 3
		while True:
			try:
				nextc = line[col]
			except IndexError:
				break
			if nextc == quoting_style and len(_ret):
				_ret = _ret[1:]
				col = col+1
			else:
				break
		snip.rv = _ret
	else:
		snip.rv = snip.c

def get_style(snip):
	style = snip.opt("g:ultisnips_python_style", "normal")

	if    style == "doxygen": return DOXYGEN
	elif  style == "sphinx": return SPHINX
	elif  style == "google": return GOOGLE
	elif  style == "numpy": return NUMPY
	elif  style == "jedi": return JEDI
	else: return NORMAL


def format_arg(arg, style):
	if style == DOXYGEN:
		return "@param %s TODO" % arg
	elif style == SPHINX:
		return ":param %s: TODO" % arg
	elif style == NORMAL:
		return ":%s: TODO" % arg
	elif style == GOOGLE:
		return "%s (TODO): TODO" % arg
	elif style == JEDI:
		return ":type %s: TODO" % arg
	elif style == NUMPY:
		return "%s : TODO" % arg


def format_return(style):
	if style == DOXYGEN:
		return "@return: TODO"
	elif style in (NORMAL, SPHINX, JEDI):
		return ":returns: TODO"
	elif style == GOOGLE:
		return "Returns: TODO"


def write_docstring_args(args, snip):
	if not args:
		snip.rv += ' {0}'.format(triple_quotes(snip))
		return

	snip.rv += '\n' + snip.mkline('', indent='')

	style = get_style(snip)

	if style == GOOGLE:
		write_google_docstring_args(args, snip)
	elif style == NUMPY:
		write_numpy_docstring_args(args, snip)
	else:
		for arg in args:
			snip += format_arg(arg, style)


def write_google_docstring_args(args, snip):
	kwargs = [arg for arg in args if arg.is_kwarg()]
	args = [arg for arg in args if not arg.is_kwarg()]

	if args:
		snip += "Args:"
		snip.shift()
		for arg in args:
			snip += format_arg(arg, GOOGLE)
		snip.unshift()
		snip.rv += '\n' + snip.mkline('', indent='')

	if kwargs:
		snip += "Kwargs:"
		snip.shift()
		for kwarg in kwargs:
			snip += format_arg(kwarg, GOOGLE)
		snip.unshift()
		snip.rv += '\n' + snip.mkline('', indent='')


def write_numpy_docstring_args(args, snip):
	if args:
		snip += "Parameters"
		snip += "----------"

	kwargs = [arg for arg in args if arg.is_kwarg()]
	args = [arg for arg in args if not arg.is_kwarg()]

	if args:
		for arg in args:
			snip += format_arg(arg, NUMPY)
	if kwargs:
		for kwarg in kwargs:
			snip += format_arg(kwarg, NUMPY) + ', optional'
	snip.rv += '\n' + snip.mkline('', indent='')


def write_init_body(args, parents, snip):
	parents = [p.strip() for p in parents.split(",")]
	parents = [p for p in parents if p != 'object']

	for p in parents:
		snip += p + ".__init__(self)"

	if parents:
		snip.rv += '\n' + snip.mkline('', indent='')

	for arg in args:
		snip += "self._%s = %s" % (arg, arg)


def write_slots_args(args, snip):
	quote = get_quoting_style(snip)
	arg_format = quote + '_%s' + quote
	args = [arg_format % arg for arg in args]
	snip += '__slots__ = (%s,)' % ', '.join(args)


def write_function_docstring(t, snip):
	"""
	Writes a function docstring with the current style.

	:param t: The values of the placeholders
	:param snip: UltiSnips.TextObjects.SnippetUtil object instance
	"""
	snip.rv = ""
	snip >> 1

	args = get_args(t[2])
	if args:
		write_docstring_args(args, snip)

	style = get_style(snip)

	if style == NUMPY:
		snip += 'Returns'
		snip += '-------'
		snip += 'TODO'
	else:
		snip += format_return(style)
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += triple_quotes(snip)

def get_dir_and_file_name(snip):
	return os.getcwd().split(os.sep)[-1] + '.' + snip.basename

endglobal

snippet classDynamicTorch "torchclass with docstrings" b
class ${1:MyClass}(${2:object}):

	`!p snip.rv = triple_quotes(snip)`${3:Docstring for $1. }`!p snip.rv = triple_quotes(snip)`

	def __init__(self$4):
		`!p snip.rv = triple_quotes(snip)`${5:TODO: to be defined1.}`!p
snip.rv = ""
snip >> 2

args = get_args(t[4])

write_docstring_args(args, snip)
if args:
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += '{0}'.format(triple_quotes(snip))

write_init_body(args, t[2], snip)
`
		$0
endsnippet
